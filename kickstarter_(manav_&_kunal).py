# -*- coding: utf-8 -*-
"""Kickstarter (Manav & Kunal).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SQ0NvAdoXUFkHaalSKDbOHuXw3QbAcH4

### Uploading kickstarter_cleaned.csv
"""

from google.colab import files
uploaded = files.upload()

"""###  Loading CSV and check basic structure"""

import pandas as pd

# Load the dataset
df = pd.read_csv('kickstarter_cleaned.csv')

# Basic info
print("Shape of the dataset:", df.shape)
print("\nColumn Names:\n", df.columns)
print("\nFirst 5 rows:")
print(df.head())
print("\nMissing values per column:\n", df.isnull().sum())

"""### Exploratory Data Analysis (EDA)

## 3A. Identifying targeted column
"""

# Check unique values in target column
print("Unique values in 'state':", df['state'].unique())
print("\nValue counts:\n", df['state'].value_counts())

"""## 3B: Class Distribution (Visualization)"""

import seaborn as sns
import matplotlib.pyplot as plt

# Plot class distribution
plt.figure(figsize=(10,6))
sns.countplot(data=df, x='state', order=df['state'].value_counts().index, palette='Set2')
plt.title('Target Class Distribution (State)')
plt.xlabel('Campaign State')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

"""## 3C: Numerical Feature Distributions (Histograms)"""

# Select only numerical columns
num_cols = df.select_dtypes(include='number').columns

# Plot histograms for all numerical columns
df[num_cols].hist(figsize=(20, 15), bins=30, color='skyblue', edgecolor='black')
plt.suptitle('Distributions of Numerical Features', fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""## 3D: Correlation Heatmap (Numerical Features)"""

import numpy as np

# Compute correlation matrix
corr_matrix = df.select_dtypes(include='number').corr()

# Plot heatmap
plt.figure(figsize=(18, 14))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True)
plt.title('Correlation Heatmap')
plt.show()

"""## 4A. Drop unwanted columns"""

drop_cols = ['name', 'created_at', 'deadline', 'launched_at', 'state_changed_at',
             'currency_symbol', 'currency_trailing_code', 'disable_communication',
             'is_launched', 'is_starrable']

df.drop(columns=drop_cols, inplace=True)
print("Remaining columns:", df.columns)

"""## 4B: Handle Missing Values"""

# Show columns with missing values
missing = df.isnull().sum()
print(missing[missing > 0])

# Drop useless column
df.drop(columns=['is_in_post_campaign_pledging_phase'], inplace=True)

# Fill numeric columns with median
for col in ['converted_pledged_amount', 'usd_pledged', 'usd_exchange_rate']:
    df[col] = df[col].fillna(df[col].median())

# Fill categorical with mode or default
df['usd_type'] = df['usd_type'].fillna(df['usd_type'].mode()[0])
df['category_name'] = df['category_name'].fillna('Unknown')

# Check if all missing handled
print("Missing values left:\n", df.isnull().sum().sum())

"""## 4C: Encode Target Column (state)"""

from sklearn.preprocessing import LabelEncoder

# Encode target column
le = LabelEncoder()
df['state_encoded'] = le.fit_transform(df['state'])

# Check mapping
state_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
print("Label Encoding Mapping:\n", state_mapping)

"""## 4D: Encode Remaining Categorical Columns"""

# List of categorical columns to encode
cat_cols = ['country', 'country_displayable_name', 'currency',
            'current_currency', 'usd_type', 'category_name']

# One-hot encode and update DataFrame
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

# Final shape
print("Final shape after encoding:", df.shape)

"""## 4E: Feature: Target Split + Train-Test Split"""

from sklearn.model_selection import train_test_split

# Split features and target
X = df.drop(columns=['state', 'state_encoded'])
y = df['state_encoded']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("Train shape:", X_train.shape)
print("Test shape:", X_test.shape)

"""###  Step 5: Machine Learning Algorithms"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Store results
results = {}

# Logistic Regression
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
results['Logistic Regression'] = accuracy_score(y_test, y_pred_lr)

# Decision Tree
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)
results['Decision Tree'] = accuracy_score(y_test, y_pred_dt)

# Random Forest
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
results['Random Forest'] = accuracy_score(y_test, y_pred_rf)

# Show accuracy
for model, acc in results.items():
    print(f"{model}: {acc:.4f}")

from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB

# Essential imports
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# Load CSV (must already be uploaded again)
df = pd.read_csv('kickstarter_cleaned.csv')

# Drop unwanted columns
drop_cols = ['name', 'created_at', 'deadline', 'launched_at', 'state_changed_at',
             'currency_symbol', 'currency_trailing_code', 'disable_communication',
             'is_launched', 'is_starrable']
df.drop(columns=drop_cols, inplace=True)

# Drop highly missing column
df.drop(columns=['is_in_post_campaign_pledging_phase'], inplace=True)

# Fill missing
for col in ['converted_pledged_amount', 'usd_pledged', 'usd_exchange_rate']:
    df[col] = df[col].fillna(df[col].median())
df['usd_type'] = df['usd_type'].fillna(df['usd_type'].mode()[0])
df['category_name'] = df['category_name'].fillna('Unknown')

# Encode target
le = LabelEncoder()
df['state_encoded'] = le.fit_transform(df['state'])

# One-hot encoding
cat_cols = ['country', 'country_displayable_name', 'currency',
            'current_currency', 'usd_type', 'category_name']
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

# Split
X = df.drop(columns=['state', 'state_encoded'])
y = df['state_encoded']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Prepare results dictionary
results = {}

print("‚úÖ Recovery done! You can now run models again.")

from sklearn.neighbors import KNeighborsClassifier

# KNN
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
results['KNN'] = accuracy_score(y_test, y_pred_knn)

print(f"KNN Accuracy: {results['KNN']:.4f}")

from sklearn.naive_bayes import GaussianNB

# Naive Bayes
nb = GaussianNB()
nb.fit(X_train, y_train)
y_pred_nb = nb.predict(X_test)
results['Naive Bayes'] = accuracy_score(y_test, y_pred_nb)

print(f"Naive Bayes Accuracy: {results['Naive Bayes']:.4f}")

from sklearn.ensemble import GradientBoostingClassifier

# Gradient Boosting
gb = GradientBoostingClassifier()
gb.fit(X_train, y_train)
y_pred_gb = gb.predict(X_test)
results['Gradient Boosting'] = accuracy_score(y_test, y_pred_gb)

print(f"Gradient Boosting Accuracy: {results['Gradient Boosting']:.4f}")

!pip install xgboost --quiet

from xgboost import XGBClassifier

# XGBoost
xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)
results['XGBoost'] = accuracy_score(y_test, y_pred_xgb)

print(f"XGBoost Accuracy: {results['XGBoost']:.4f}")

!pip install lightgbm --quiet

from lightgbm import LGBMClassifier

# LightGBM
lgb = LGBMClassifier()
lgb.fit(X_train, y_train)
y_pred_lgb = lgb.predict(X_test)
results['LightGBM'] = accuracy_score(y_test, y_pred_lgb)

print(f"LightGBM Accuracy: {results['LightGBM']:.4f}")

# Step 1: Imports
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score

# Step 2: Load Data
df = pd.read_csv('kickstarter_cleaned.csv')

# Step 3: Drop unwanted columns
drop_cols = ['name', 'created_at', 'deadline', 'launched_at', 'state_changed_at',
             'currency_symbol', 'currency_trailing_code', 'disable_communication',
             'is_launched', 'is_starrable', 'is_in_post_campaign_pledging_phase']
df.drop(columns=drop_cols, inplace=True)

# Step 4: Fill missing values
df['converted_pledged_amount'].fillna(df['converted_pledged_amount'].median(), inplace=True)
df['usd_pledged'].fillna(df['usd_pledged'].median(), inplace=True)
df['usd_exchange_rate'].fillna(df['usd_exchange_rate'].median(), inplace=True)
df['usd_type'].fillna(df['usd_type'].mode()[0], inplace=True)
df['category_name'].fillna('Unknown', inplace=True)

# Step 5: Encode target
le = LabelEncoder()
df['state_encoded'] = le.fit_transform(df['state'])

# Step 6: One-hot encoding for categoricals
cat_cols = ['country', 'country_displayable_name', 'currency',
            'current_currency', 'usd_type', 'category_name']
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

# Step 7: Split data
X = df.drop(columns=['state', 'state_encoded'])
y = df['state_encoded']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Step 8: Results dictionary
results = {}

print("‚úÖ Recovery complete. Ready for Extra Trees and Voting Classifier.")

from sklearn.ensemble import ExtraTreesClassifier

et = ExtraTreesClassifier()
et.fit(X_train, y_train)
y_pred_et = et.predict(X_test)
results['Extra Trees'] = accuracy_score(y_test, y_pred_et)

print(f"Extra Trees Accuracy: {results['Extra Trees']:.4f}")

from sklearn.ensemble import VotingClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier

# Voting Classifier with top 3 models
voting = VotingClassifier(estimators=[
    ('rf', RandomForestClassifier()),
    ('gb', GradientBoostingClassifier()),
    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))
], voting='soft')

voting.fit(X_train, y_train)
y_pred_vote = voting.predict(X_test)
results['Voting Ensemble'] = accuracy_score(y_test, y_pred_vote)

print(f"Voting Ensemble Accuracy: {results['Voting Ensemble']:.4f}")

results = {
    'XGBoost': 0.9554,
    'Voting Ensemble': 0.9548,
    'Gradient Boosting': 0.9526,
    'Random Forest': 0.9496,
    'Extra Trees': 0.9411,
    'KNN': 0.9317,
    'Decision Tree': 0.9254,
    'Logistic Regression': 0.8659,
    'LightGBM': 0.8408,
    'Naive Bayes': 0.4153
}

import matplotlib.pyplot as plt

model_names = list(results.keys())
accuracies = list(results.values())

plt.figure(figsize=(10,6))
bars = plt.barh(model_names, accuracies, color='skyblue')
plt.xlabel('Accuracy')
plt.title('Model Accuracy Comparison')

for bar in bars:
    plt.text(bar.get_width() + 0.005, bar.get_y() + 0.3, f'{bar.get_width():.4f}')

plt.xlim(0.4, 1.0)
plt.gca().invert_yaxis()
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.show()

# Check if train-test split already exists
try:
    print("‚úÖ X_train shape:", X_train.shape)
    print("‚úÖ y_train shape:", y_train.shape)
    print("‚úÖ X_test shape:", X_test.shape)
    print("‚úÖ y_test shape:", y_test.shape)
except NameError:
    print("‚ùå Train-test split not found. We need to split the data.")

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# Initialize models
rf = RandomForestClassifier(n_estimators=200, random_state=42)
xgb = XGBClassifier(n_estimators=200, use_label_encoder=False, eval_metric='logloss', random_state=42)
gb = GradientBoostingClassifier(n_estimators=200, random_state=42)

# Voting classifier (ensemble)
voting = VotingClassifier(estimators=[('rf', rf), ('xgb', xgb), ('gb', gb)], voting='soft')

# Train
voting.fit(X_train, y_train)

# Predict
y_pred = voting.predict(X_test)

# Accuracy
acc = accuracy_score(y_test, y_pred)
print(f"üìä Ensemble Voting Classifier Accuracy: {acc * 100:.2f}%")

import pandas as pd

# Load the cleaned dataset
df_cleaned = pd.read_csv("kickstarter_cleaned.csv")

# Show first 10 rows
df_cleaned.head(10)

